---
id: 163
title: 'On Rigor'
date: '2014-02-23T18:16:52-05:00'
author: 'Teddy Svoronos'
layout: post
guid: 'http://teddysvoronos.com/?p=163'
permalink: /2014/02/23/on-rigor-2/
categories:
    - Commentary
tags:
    - 'external validity'
    - 'internal validity'
    - 'program evaluation'
---

<p>Lant Pritchett wrote <a href="http://buildingstatecapability.com/2014/02/20/rigorous-evidence-isnt/">a piece for the Building State Capacity blog</a> about the notion of &#8220;rigorous evidence.&#8221; At the risk of putting words in his mouth, my sense is that his argument boils down to this: <em>promoters of evidence-based policy overplay their hands by focusing exclusively on internal validity</em><a href="#fn:1" id="fnref:1" title="see footnote" class="footnote">[1]</a>. He says as much in his post:</p>

<blockquote>
<p>Evidence would be &#8220;rigorous&#8221; about <em>predicting the future</em> impact of the adoption of a policy only if the conditions under which the policy was to be implemented were <em>exactly the same in every relevant dimension</em> as that under which the &#8220;rigorous&#8221; evidence was generated. But that can never be so because neither economics—nor any other social science—have theoretically sound and empirically validated <em>invariance laws</em> that specify what &#8220;exactly the same&#8221; conditions would be.</p>
</blockquote>

<p>Pritchett raises an important point; our understanding of internal validity and our methods for assessing it are far more developed than that of external validity<a href="#fn:2" id="fnref:2" title="see footnote" class="footnote">[2]</a>. However, I can’t help but feel that Pritchett is overplaying his hand as well. We consider a study to be internally valid if our comparison groups are equivalent <em>in expectation</em>, not if they are exactly the same in every relevant dimension. This may seem like mincing words, but there’s a distinction between <em>equivalence</em> and <em>plausibly arguing the absence of bias</em>. The latter is the standard to which we hold studies when assessing internal validity, and we should do the same for external validity. Still, the point remains that our understanding of external validity is far removed from even this weaker definition.</p>

<p><strong>Link</strong>: <a href="http://buildingstatecapability.com/2014/02/20/rigorous-evidence-isnt/">Rigorous Evidence Isn’t</a></p>

<div class="footnotes">
<hr />
<ol>

<li id="fn:1">
<p><a href="http://en.wikipedia.org/wiki/External_validity#External.2C_internal.2C_and_ecological_validity">Wikipedia’s entry on external validity vs. internal validity</a> provides a nice overview of the tension for those unfamiliar with the concepts. <a href="#fnref:1" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

<li id="fn:2">
<p>A <a href="http://www.nber.org/papers/w18373">recent working paper by Hunt Alcott and Sendhil Mullainathan</a> is an interesting foray into developing metrics for external validity. Unfortunately, these metrics seem to require a whole heap of data that is rarely available for a single intervention. <a href="#fnref:2" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

</ol>
</div>